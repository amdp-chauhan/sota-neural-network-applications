{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Notebook is created just for learning and experimentation purpose. Examples and the implementation is based on various research available on the internet and Tensorflow documentation. For now, it just provides a beginner level understanding and in future will lead to a more advanced solution.","metadata":{}},{"cell_type":"markdown","source":"## Library Import ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:24:17.386676Z","iopub.execute_input":"2022-07-24T15:24:17.387167Z","iopub.status.idle":"2022-07-24T15:24:17.394674Z","shell.execute_reply.started":"2022-07-24T15:24:17.387129Z","shell.execute_reply":"2022-07-24T15:24:17.393360Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"markdown","source":"We are going to use the MNIST dataset where image resolution is 28x28.","metadata":{}},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\nlabels_dict = {\n    '0': 'T-shirt/top',\n    '1': 'Trouser',\n    '2': 'Pullover',\n    '3': 'Dress',\n    '4': 'Coat',\n    '5': 'Sandal',\n    '6': 'Shirt',\n    '7': 'Sneaker',\n    '8': 'Bag',\n    '9': 'Ankle boot'\n}\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nprint (x_train.shape)\nprint (x_test.shape)\n\n# display original\nn = 5\nfor i in range(n):\n    ax = plt.subplot(1, n, i+1)\n    select_img_index = np.random.randint(x_test.shape[0])\n    plt.imshow(x_test[select_img_index])\n    plt.title(labels_dict[str(y_test[select_img_index])])\n    # plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:42:20.541473Z","iopub.execute_input":"2022-07-24T15:42:20.542483Z","iopub.status.idle":"2022-07-24T15:42:21.338699Z","shell.execute_reply.started":"2022-07-24T15:42:20.542443Z","shell.execute_reply":"2022-07-24T15:42:21.337573Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# <font color='green'>**Image Compression**</font> ","metadata":{}},{"cell_type":"markdown","source":"Define an autoencoder with two Dense layers: an encoder, which compresses the images into a 64 dimensional latent vector, and a decoder, that reconstructs the original image from the latent space.","metadata":{}},{"cell_type":"code","source":"latent_dim = 64 \n\nclass Autoencoder(Model):\n    def __init__(self, latent_dim):\n        super(Autoencoder, self).__init__()\n        self.latent_dim = latent_dim   \n        self.encoder = tf.keras.Sequential([\n          layers.Flatten(),\n          layers.Dense(latent_dim, activation='relu'),\n        ])\n        self.decoder = tf.keras.Sequential([\n          layers.Dense(784, activation='sigmoid'),\n          layers.Reshape((28, 28))\n        ])\n\n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nautoencoder = Autoencoder(latent_dim)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:42:22.259279Z","iopub.execute_input":"2022-07-24T15:42:22.259668Z","iopub.status.idle":"2022-07-24T15:42:22.281282Z","shell.execute_reply.started":"2022-07-24T15:42:22.259636Z","shell.execute_reply":"2022-07-24T15:42:22.279832Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:28:05.833832Z","iopub.execute_input":"2022-07-24T15:28:05.834241Z","iopub.status.idle":"2022-07-24T15:28:05.858412Z","shell.execute_reply.started":"2022-07-24T15:28:05.834208Z","shell.execute_reply":"2022-07-24T15:28:05.857458Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Train the model using x_train as both the input and the target. The encoder will learn to compress the dataset from 784 dimensions to the latent space, and the decoder will learn to reconstruct the original images. .","metadata":{}},{"cell_type":"code","source":"autoencoder.fit(x_train, x_train,\n                epochs=10,\n                shuffle=True,\n                validation_data=(x_test, x_test))","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:28:17.711804Z","iopub.execute_input":"2022-07-24T15:28:17.712194Z","iopub.status.idle":"2022-07-24T15:29:40.760732Z","shell.execute_reply.started":"2022-07-24T15:28:17.712163Z","shell.execute_reply":"2022-07-24T15:29:40.759862Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"autoencoder.encoder.summary(), autoencoder.decoder.summary();","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:53:12.303908Z","iopub.execute_input":"2022-07-24T15:53:12.304832Z","iopub.status.idle":"2022-07-24T15:53:12.311165Z","shell.execute_reply.started":"2022-07-24T15:53:12.304794Z","shell.execute_reply":"2022-07-24T15:53:12.310137Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"Now that the model is trained, let's test it by encoding and decoding images from the test set.","metadata":{}},{"cell_type":"code","source":"encoded_imgs = autoencoder.encoder(x_test).numpy()\ndecoded_imgs = autoencoder.decoder(encoded_imgs).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:30:08.427769Z","iopub.execute_input":"2022-07-24T15:30:08.428189Z","iopub.status.idle":"2022-07-24T15:30:08.580625Z","shell.execute_reply.started":"2022-07-24T15:30:08.428156Z","shell.execute_reply":"2022-07-24T15:30:08.579442Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"n = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    select_img_index = np.random.randint(x_test.shape[0])\n    plt.imshow(x_test[select_img_index])\n    plt.title(\"original\")\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[select_img_index])\n    plt.title(\"reconstructed\")\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:54:44.117686Z","iopub.execute_input":"2022-07-24T15:54:44.118077Z","iopub.status.idle":"2022-07-24T15:54:45.423296Z","shell.execute_reply.started":"2022-07-24T15:54:44.118036Z","shell.execute_reply":"2022-07-24T15:54:45.422178Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"# <font color='green'>**Image Denoising (using Convolution Autoencoder)**</font> ","metadata":{}},{"cell_type":"markdown","source":"We can use Autoencoders to clean images by removing the unwanted noise in the given input. In the below steps we'll introduce this noise using synthetic methods, and later will train an Autoencoder network to produce noise free images.","metadata":{}},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:46:56.847892Z","iopub.execute_input":"2022-07-24T15:46:56.848736Z","iopub.status.idle":"2022-07-24T15:46:57.296012Z","shell.execute_reply.started":"2022-07-24T15:46:56.848696Z","shell.execute_reply":"2022-07-24T15:46:57.294919Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\n\nx_train = x_train[..., tf.newaxis]\nx_test = x_test[..., tf.newaxis]\n\nprint(x_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:46:57.298290Z","iopub.execute_input":"2022-07-24T15:46:57.298727Z","iopub.status.idle":"2022-07-24T15:46:57.382817Z","shell.execute_reply.started":"2022-07-24T15:46:57.298684Z","shell.execute_reply":"2022-07-24T15:46:57.381733Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"Adding random noise to the images","metadata":{}},{"cell_type":"code","source":"noise_factor = 0.3\nx_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \nx_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n\nx_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\nx_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)\n\n\n# display original + noisy image\nn = 5\nfor i in range(n):\n    # original \n    ax = plt.subplot(2, n, i+1)\n    select_img_index = np.random.randint(x_test.shape[0])\n    plt.imshow(tf.squeeze(x_test[select_img_index]))\n    plt.title(labels_dict[str(y_test[select_img_index])])\n    # plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # noisy\n    ax = plt.subplot(2, n, i+1+n)\n    plt.imshow(tf.squeeze(x_test_noisy[select_img_index]))\n    plt.title('+ noise')\n    # plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:46:57.384654Z","iopub.execute_input":"2022-07-24T15:46:57.384978Z","iopub.status.idle":"2022-07-24T15:46:58.476406Z","shell.execute_reply.started":"2022-07-24T15:46:57.384948Z","shell.execute_reply":"2022-07-24T15:46:58.475331Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"In this example, we will train a convolutional autoencoder using Conv2D layers in the encoder, and Conv2DTranspose layers in the decoder.","metadata":{}},{"cell_type":"code","source":"class Denoise(Model):\n    def __init__(self):\n        super(Denoise, self).__init__()\n        self.encoder = tf.keras.Sequential([\n          layers.Input(shape=(28, 28, 1)),\n          layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n          layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n        \n        # The decoder upsamples the images back from 7x7 to 28x28.\n        self.decoder = tf.keras.Sequential([\n          layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n          layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n          layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n\n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nautoencoder = Denoise()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:48:24.437554Z","iopub.execute_input":"2022-07-24T15:48:24.437971Z","iopub.status.idle":"2022-07-24T15:48:24.484871Z","shell.execute_reply.started":"2022-07-24T15:48:24.437939Z","shell.execute_reply":"2022-07-24T15:48:24.484011Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:48:42.734647Z","iopub.execute_input":"2022-07-24T15:48:42.735020Z","iopub.status.idle":"2022-07-24T15:48:42.745400Z","shell.execute_reply.started":"2022-07-24T15:48:42.734991Z","shell.execute_reply":"2022-07-24T15:48:42.744439Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(x_train_noisy, x_train,\n                epochs=10,\n                shuffle=True,\n                validation_data=(x_test_noisy, x_test))","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:48:44.947347Z","iopub.execute_input":"2022-07-24T15:48:44.947767Z","iopub.status.idle":"2022-07-24T15:51:51.051751Z","shell.execute_reply.started":"2022-07-24T15:48:44.947733Z","shell.execute_reply":"2022-07-24T15:51:51.050770Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"autoencoder.encoder.summary(), autoencoder.decoder.summary();","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:52:48.280477Z","iopub.execute_input":"2022-07-24T15:52:48.280831Z","iopub.status.idle":"2022-07-24T15:52:48.287554Z","shell.execute_reply.started":"2022-07-24T15:52:48.280803Z","shell.execute_reply":"2022-07-24T15:52:48.286675Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\ndecoded_imgs = autoencoder.decoder(encoded_imgs).numpy()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:53:53.023336Z","iopub.execute_input":"2022-07-24T15:53:53.023724Z","iopub.status.idle":"2022-07-24T15:53:54.280939Z","shell.execute_reply.started":"2022-07-24T15:53:53.023692Z","shell.execute_reply":"2022-07-24T15:53:54.279900Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"n = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    select_img_index = np.random.randint(x_test.shape[0])\n    plt.imshow(tf.squeeze(x_test_noisy[select_img_index]))\n    plt.title(\"original\")\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(tf.squeeze(decoded_imgs[select_img_index]))\n    plt.title(\"reconstructed\")\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T15:55:37.774454Z","iopub.execute_input":"2022-07-24T15:55:37.774845Z","iopub.status.idle":"2022-07-24T15:55:38.617493Z","shell.execute_reply.started":"2022-07-24T15:55:37.774812Z","shell.execute_reply":"2022-07-24T15:55:38.616433Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"# <font color='green'>**Anomaly detection (on the ECG5000 dataset)**</font> ","metadata":{}},{"cell_type":"markdown","source":"About dataset: http://www.timeseriesclassification.com/description.php?Dataset=ECG5000\n        \n*         The original dataset for \"ECG5000\" is a 20-hour long ECG downloaded from Physionet. \n*         The data was pre-processed in two steps: (1) extract each heartbeat, (2) make each heartbeat equal length using interpolation.\n\nThis dataset contains 5,000 Electrocardiograms, each with 140 data points. \nHere, we'll use a simplified version of the dataset, where each example has been labeled either 0 (corresponding to an abnormal rhythm), or 1 (corresponding to a normal rhythm). You are interested in identifying the abnormal rhythms.","metadata":{}},{"cell_type":"code","source":"# Download the dataset\ndataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\nraw_data = dataframe.values\nprint(dataframe.shape)\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:38:09.434317Z","iopub.execute_input":"2022-07-24T16:38:09.434680Z","iopub.status.idle":"2022-07-24T16:38:09.725981Z","shell.execute_reply.started":"2022-07-24T16:38:09.434648Z","shell.execute_reply":"2022-07-24T16:38:09.724857Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# The last element contains the labels\nlabels = raw_data[:, -1]\n\n# The other data points are the electrocadriogram data\ndata = raw_data[:, 0:-1]\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(\n    data, labels, test_size=0.2, random_state=21\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:00:15.493603Z","iopub.execute_input":"2022-07-24T17:00:15.493969Z","iopub.status.idle":"2022-07-24T17:00:15.507370Z","shell.execute_reply.started":"2022-07-24T17:00:15.493940Z","shell.execute_reply":"2022-07-24T17:00:15.506252Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# Normalize to 0 - 1\nmin_val = tf.reduce_min(train_data)\nmax_val = tf.reduce_max(train_data)\n\ntrain_data = (train_data - min_val) / (max_val - min_val)\ntest_data = (test_data - min_val) / (max_val - min_val)\n\ntrain_data = tf.cast(train_data, tf.float32)\ntest_data = tf.cast(test_data, tf.float32)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:00:16.073420Z","iopub.execute_input":"2022-07-24T17:00:16.074483Z","iopub.status.idle":"2022-07-24T17:00:16.093203Z","shell.execute_reply.started":"2022-07-24T17:00:16.074442Z","shell.execute_reply":"2022-07-24T17:00:16.091839Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"train_labels = train_labels.astype(bool)\ntest_labels = test_labels.astype(bool)\n\nnormal_train_data = train_data[train_labels]\nnormal_test_data = test_data[test_labels]\n\nanomalous_train_data = train_data[~train_labels]\nanomalous_test_data = test_data[~test_labels]\n\ntrain_data, normal_test_data, anomalous_train_data","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:00:17.763659Z","iopub.execute_input":"2022-07-24T17:00:17.764069Z","iopub.status.idle":"2022-07-24T17:00:17.786219Z","shell.execute_reply.started":"2022-07-24T17:00:17.764031Z","shell.execute_reply":"2022-07-24T17:00:17.784761Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# Plot a normal ECG.\n\n\nplt.grid()\nselected_index = np.random.randint(normal_train_data.shape[0])\nplt.plot(np.arange(140), normal_train_data[selected_index])\nplt.title(f\"A Normal ECG - Index:{selected_index}\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:04:17.901284Z","iopub.execute_input":"2022-07-24T17:04:17.901651Z","iopub.status.idle":"2022-07-24T17:04:18.095586Z","shell.execute_reply.started":"2022-07-24T17:04:17.901622Z","shell.execute_reply":"2022-07-24T17:04:18.094765Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"# Plot an anomalous ECG.\n\nplt.grid()\nplt.plot(np.arange(140), anomalous_train_data[0])\nplt.title(\"An Anomalous ECG\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:04:35.237752Z","iopub.execute_input":"2022-07-24T17:04:35.238498Z","iopub.status.idle":"2022-07-24T17:04:35.422619Z","shell.execute_reply.started":"2022-07-24T17:04:35.238454Z","shell.execute_reply":"2022-07-24T17:04:35.421614Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"### Build the model","metadata":{}},{"cell_type":"code","source":"class AnomalyDetector(Model):\n    def __init__(self):\n        super(AnomalyDetector, self).__init__()\n        self.encoder = tf.keras.Sequential([\n          layers.Dense(32, activation=\"relu\"),\n          layers.Dense(16, activation=\"relu\"),\n          layers.Dense(8, activation=\"relu\")])\n\n        self.decoder = tf.keras.Sequential([\n          layers.Dense(16, activation=\"relu\"),\n          layers.Dense(32, activation=\"relu\"),\n          layers.Dense(140, activation=\"sigmoid\")])\n\n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nautoencoder = AnomalyDetector()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:09:15.257260Z","iopub.execute_input":"2022-07-24T17:09:15.257669Z","iopub.status.idle":"2022-07-24T17:09:15.281451Z","shell.execute_reply.started":"2022-07-24T17:09:15.257635Z","shell.execute_reply":"2022-07-24T17:09:15.280488Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(optimizer='adam', loss='mae')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:11:26.292030Z","iopub.execute_input":"2022-07-24T17:11:26.292548Z","iopub.status.idle":"2022-07-24T17:11:26.305874Z","shell.execute_reply.started":"2022-07-24T17:11:26.292503Z","shell.execute_reply":"2022-07-24T17:11:26.305040Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"history = autoencoder.fit(normal_train_data,\n                          normal_train_data,\n                          epochs=20,\n                          batch_size=512,\n                          validation_data=(test_data, test_data),\n                          shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:11:26.718769Z","iopub.execute_input":"2022-07-24T17:11:26.719602Z","iopub.status.idle":"2022-07-24T17:11:29.878379Z","shell.execute_reply.started":"2022-07-24T17:11:26.719555Z","shell.execute_reply":"2022-07-24T17:11:29.877219Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"Notice that the autoencoder is trained using only the normal ECGs, but is evaluated using the full test set.\n","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history[\"loss\"], label=\"Training Loss\")\nplt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:11:49.005479Z","iopub.execute_input":"2022-07-24T17:11:49.005864Z","iopub.status.idle":"2022-07-24T17:11:49.225504Z","shell.execute_reply.started":"2022-07-24T17:11:49.005834Z","shell.execute_reply":"2022-07-24T17:11:49.224326Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"encoded_data = autoencoder.encoder(normal_test_data).numpy()\ndecoded_data = autoencoder.decoder(encoded_data).numpy()\n\nselected_index = np.random.randint(normal_test_data.shape[0])\n\nplt.plot(normal_test_data[selected_index], 'b')\nplt.plot(decoded_data[selected_index], 'r')\nplt.title(f'Normal Test Example - {selected_index}')\nplt.fill_between(np.arange(140), decoded_data[selected_index], normal_test_data[selected_index], color='lightcoral')\nplt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:17:12.054331Z","iopub.execute_input":"2022-07-24T17:17:12.054716Z","iopub.status.idle":"2022-07-24T17:17:12.279223Z","shell.execute_reply.started":"2022-07-24T17:17:12.054686Z","shell.execute_reply":"2022-07-24T17:17:12.278143Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"# Create a similar plot, this time for an anomalous test example.\n\nencoded_data = autoencoder.encoder(anomalous_test_data).numpy()\ndecoded_data = autoencoder.decoder(encoded_data).numpy()\n\nselected_index = np.random.randint(anomalous_test_data.shape[0])\n\nplt.plot(anomalous_test_data[selected_index], 'b')\nplt.plot(decoded_data[selected_index], 'r')\nplt.title(f'Normal Test Example - {selected_index}')\nplt.fill_between(np.arange(140), decoded_data[selected_index], anomalous_test_data[selected_index], color='lightcoral')\nplt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:18:54.442575Z","iopub.execute_input":"2022-07-24T17:18:54.443555Z","iopub.status.idle":"2022-07-24T17:18:54.679897Z","shell.execute_reply.started":"2022-07-24T17:18:54.443513Z","shell.execute_reply":"2022-07-24T17:18:54.679151Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"markdown","source":"ECG can be considered as anomalous if the reconstruction error is greater than one standard deviation from the normal input observation.","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:19:58.723574Z","iopub.execute_input":"2022-07-24T17:19:58.723952Z","iopub.status.idle":"2022-07-24T17:19:58.731742Z","shell.execute_reply.started":"2022-07-24T17:19:58.723921Z","shell.execute_reply":"2022-07-24T17:19:58.730185Z"}}},{"cell_type":"markdown","source":"We can calculate the MAE between reconstructions and the normalized ECG values. Mean and Std. of this MAE can be used to decide the MAE threshold value above which a datapoint should be classified as anomaly. ","metadata":{}},{"cell_type":"code","source":"reconstructions = autoencoder.predict(normal_train_data)\ntrain_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n\nplt.hist(train_loss, bins=50)\nplt.xlabel(\"Train loss\")\nplt.ylabel(\"No of examples\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:45:20.386648Z","iopub.execute_input":"2022-07-24T17:45:20.387066Z","iopub.status.idle":"2022-07-24T17:45:21.109829Z","shell.execute_reply.started":"2022-07-24T17:45:20.387031Z","shell.execute_reply":"2022-07-24T17:45:21.108627Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"markdown","source":"Note that, this train loss distribution is obtained for the normal ECG training examples, and here we can clearly see that most of the points give MAE < ~0.04. So our threshold can be decided nearby only.","metadata":{}},{"cell_type":"code","source":"threshold = np.mean(train_loss) + np.std(train_loss)\nprint(\"Threshold: \", threshold)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:47:40.871595Z","iopub.execute_input":"2022-07-24T17:47:40.871993Z","iopub.status.idle":"2022-07-24T17:47:40.878557Z","shell.execute_reply.started":"2022-07-24T17:47:40.871960Z","shell.execute_reply":"2022-07-24T17:47:40.877781Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":"**Note:** There are other strategies you could use to select a threshold value above which test examples should be classified as anomalous, the correct approach will depend on your dataset. You can learn more with the links at the end of this tutorial.","metadata":{}},{"cell_type":"code","source":"reconstructions = autoencoder.predict(anomalous_test_data)\ntest_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)\n\nplt.hist(test_loss[None, :], bins=50)\nplt.xlabel(\"Test loss\")\nplt.ylabel(\"No of examples\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:48:49.175612Z","iopub.execute_input":"2022-07-24T17:48:49.175990Z","iopub.status.idle":"2022-07-24T17:48:49.461275Z","shell.execute_reply.started":"2022-07-24T17:48:49.175960Z","shell.execute_reply":"2022-07-24T17:48:49.460252Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"markdown","source":"If we examine the reconstruction error for the anomalous examples in the test set, we notice most have greater reconstruction error than the threshold. By varing the threshold, we can adjust the precision and recall of our classifier.","metadata":{}},{"cell_type":"markdown","source":"#### Classify an ECG as an anomaly if the reconstruction error is greater than the threshold.","metadata":{}},{"cell_type":"code","source":"def predict(model, data, threshold):\n    reconstructions = model(data)\n    loss = tf.keras.losses.mae(reconstructions, data)\n    return tf.math.less(loss, threshold)\n\ndef print_stats(predictions, labels):\n    print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n    print(\"Precision = {}\".format(precision_score(labels, predictions)))\n    print(\"Recall = {}\".format(recall_score(labels, predictions)))\n    \npreds = predict(autoencoder, test_data, threshold)\nprint_stats(preds, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:50:54.628207Z","iopub.execute_input":"2022-07-24T17:50:54.628582Z","iopub.status.idle":"2022-07-24T17:50:54.657647Z","shell.execute_reply.started":"2022-07-24T17:50:54.628543Z","shell.execute_reply":"2022-07-24T17:50:54.656787Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"markdown","source":"Later, let's look at few custom and advanced solutions. Don't forget to upvote if you find it useful. ","metadata":{}}]}